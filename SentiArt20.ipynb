{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python3\n", "# -*- coding: utf-8 -*-\n", "\"\"\"\n", "Created on Mon Nov 16 09:24:58 2020\n", "SentiArt20.py basic sentiment analysis tool for literary texts\n", "@author: ajacobs@zedat.fu-berlin.de\n", "\"\"\"\n", "# get packages\n", "import os,codecs\n", "import pandas as pd\n", "import nltk\n", "from nltk import*\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["open a short sample text"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fn = 'momo_4s.txt'\n", "with codecs.open(fn,'r','utf-8') as f:\n", "    raw = f.read().replace('\\n',' ')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n get the table with sentiment values (e.g., AAPz, fear_z). <br>\n", "these are based on a vector space model (w2v, skipgram, 300d) and the label list published in:<br>\n", "https://www.frontiersin.org/articles/10.3389/fnhum.2017.00622/full#supplementary-material; https://www.frontiersin.org/articles/10.3389/fpsyg.2020.574746/full<br>\n", "the values for each word are: AAPz,ang_z,fear_z,disg_z,hap_z,sad_z,surp_z<br>\n", "they provide the affective-aesthetic potential (AAP) and discrete emotion values (anger, fear, disgust, sadness and surprise), all standardized (z-values), <br>\n", "for each word, based on their semantic relatedness (as computed by w2v) with labels (semantic anchors) described in the publications mentioned in readme.md<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["TC = '120kSentiArt_DE.xlsx' # for German texts\n", "#TC = '250kSentiArt_EN.xlsx' # for English texts\n", "sa = pd.read_excel(TC)                     \n", "sents = sent_tokenize(raw)\n", "tokens = [word_tokenize(s) for s in sents]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ompute mean AAPz (or mean ang_z etc.) per sentence"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sent_mean_AAPz = []\n", "for t in tokens:\n", "    dt = sa.query('wordUC in @t')\n", "    sent_mean_AAPz.append(dt.AAPz.mean())\n", "# print results\n", "for s,aapz in zip(sents,sent_mean_AAPz):\n", "    print(s,round(aapz,3))\n", "# save results as pandas df\n", "df = pd.DataFrame()\n", "df['sent'] = sents\n", "df['AAPz'] = sent_mean_AAPz\n", "df.to_csv('results.txt')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot AAPz, fear_z etc."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.AAPz.hist()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.set_index(df.index,inplace=True)\n", "df.plot(kind='bar',alpha=0.75, rot=0)\n", "plt.xlabel(\"Sentence #\")\n", "plt.ylabel(\"Sentiment Value (z)\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["et most beautiful and ugliest words in corpus"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["topb = sa.sort_values(by=['AAPz']).tail()\n", "print('top beauty words','\\n',topb.word)\n", "print()\n", "topu = sa.sort_values(by=['AAPz']).head()\n", "print('top ugly words','\\n',topu.word)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["et most beautiful and ugliest sents in text"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('top beauty sent','\\n',df.sort_values(by=['AAPz']).tail(1))\n", "print()\n", "print('top ugly sent','\\n',df.sort_values(by=['AAPz']).head(1))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}